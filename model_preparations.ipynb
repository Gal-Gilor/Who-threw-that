{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "* Rename columns\n",
    "* Focus on acceleration and ignore the angular velocity (for now)\n",
    "* Smoothen the values to help reduce noise\n",
    "* Calculate the acceleration vector magnitude\n",
    "* Focusing on readings near the acceleration peak\n",
    "* Scale the data\n",
    "* Create a training and testing datasets\n",
    "    * Each row would contain the acceleration magnitudes for a single throw (file)\n",
    "    * Append the radar gun reading to the observations\n",
    "    * Optional: Add wrist velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib as jb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from typing import Optional, List, Dict, Union\n",
    "\n",
    "from scipy.integrate import cumtrapz # intergrate trapezoidal rule\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# graph styling\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-dark')\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_gun = pd.read_csv('Speed-Filenames.csv')\n",
    "radar_gun = radar_gun.sort_values(by=['Speed']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_observation_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Rename the column names in the individual throws dataframes\n",
    "    Note: Specific to this kaggle dataset columns\n",
    "    inputs:\n",
    "        df: dataframe, raw imu file data\n",
    "    '''\n",
    "    return df.rename(columns={\n",
    "        \"Time_s_\": \"time\", \n",
    "        \"Acc_x_m_s_2_\": \"acc_x\",\n",
    "        \"Acc_y_m_s_2_\": \"acc_y\",\n",
    "        \"Acc_z_m_s_2_\": \"acc_z\",\n",
    "        \"Gyro_x_1_s_\": \"gyro_x\",\n",
    "        \"Gyro_y_1_s_\": \"gyro_y\",\n",
    "        \"Gyro_z_1_s_\": \"gyro_z\",\n",
    "    })\n",
    "\n",
    "def filter_acceleration_columns(df: pd.DataFrame, regex: Optional[str] = 'acc.*') -> pd.DataFrame:\n",
    "    '''\n",
    "    Keeps only the acceleration columns (start with acc)\n",
    "    inputs:\n",
    "        df: dataframe, renamed columns raw imu file data\n",
    "        regex: string, a regular expression 'acc.*' by default\n",
    "    '''\n",
    "    return df.filter(regex=regex)\n",
    "\n",
    "def rolling_average(vector: np.array, window_width: Optional[int] = 151) -> np.array:\n",
    "    '''\n",
    "    Calculate the rolling average of a vector\n",
    "    input:\n",
    "        vector: numpy array, input to calculate the moving average\n",
    "        window_with: integer, defines how many units in the vector to average together 151 items by default\n",
    "    '''\n",
    "    cumsum_vec = np.cumsum(np.insert(vector, 0, 0))\n",
    "    ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "    return ma_vec\n",
    "\n",
    "def calculate_vector_magnitude(df: pd.DataFrame, \n",
    "                               x_vector: Optional[str] = 'acc_x',\n",
    "                               y_vector: Optional[str] = 'acc_y',\n",
    "                               z_vector: Optional[str] = 'acc_z') -> np.array:\n",
    "    '''\n",
    "    Calculate the magnitude of a 3D vector (x, y, z axis)\n",
    "    The square root the sum of the squared vector values\n",
    "    sqrt(Ax^2 + Ay^2 + Az^2)\n",
    "    input:\n",
    "        df: df: dataframe, renamed columns raw imu file data\n",
    "        x_vector: string, x axis column name 'acc_x' by default\n",
    "        y_vector: string, y axis column name 'acc_y' by default\n",
    "        z_vector: string, z axis column name 'acc_z' by default    \n",
    "    '''\n",
    "    \n",
    "    # square the vectors\n",
    "    x_squared = df[x_vector] ** 2\n",
    "    y_squared = df[y_vector] ** 2\n",
    "    z_squared = df[z_vector] ** 2\n",
    "    \n",
    "    # square root the sum of squared values (magnitude) \n",
    "    return np.sqrt(sum([x_squared + y_squared + z_squared]))\n",
    "\n",
    "def identify_maximum_acceleration(df: pd.DataFrame, \n",
    "                                  numeric_column: Optional[str] = 'acc_x') -> pd.DataFrame:\n",
    "    '''\n",
    "    Slices a dataframe to just 100 observations before, and after the maximum value of a numeric value\n",
    "    input:\n",
    "        df: dataframe, renamed columns raw imu file data\n",
    "        numeric_column: string, numeric values column name 'acc_x' by default\n",
    "    '''\n",
    "    # find the index for the maximum value in the numeric column\n",
    "    maximum_idx = df[numeric_column].idxmax()\n",
    "    \n",
    "    # capture 100 frames before and after the maximum value\n",
    "    maximum = df.loc[maximum_idx - 100: maximum_idx + 100]\n",
    "    return maximum\n",
    "\n",
    "def intergrate_column(df: pd.DataFrame, \n",
    "                      columns_to_integrate: Optional[List[str]] = ['acc_x', 'acc_y', 'acc_z'],\n",
    "                      integrated_columns_names: Optional[List[str]] = ['veloc_x', 'veloc_y', 'veloc_z'],\n",
    "                      x_column: Optional[str] = 'time') -> pd.DataFrame:\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    assert len(integrated_columns_names) == len(columns_to_integrate), \\\n",
    "        \"The new columns name array should be the same length as the columns to integerate array\"   \n",
    "    \n",
    "    for i in range(len(integrated_columns_names)):\n",
    "        df[integrated_columns_names[i]] = np.append(0.0, cumtrapz(df[columns_to_integrate[i]], x=df[x_column])) \n",
    "    return df\n",
    "\n",
    "def scale_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # refrence column names \n",
    "    column_names = df.columns.tolist()\n",
    "    \n",
    "    # instanciate scaler and fit to the dataframe\n",
    "    scaler = StandardScaler()  \n",
    "    scaled_features = scaler.fit_transform(df)\n",
    "    \n",
    "    # create a new dataframe with the scaled features\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=column_names, index=df.index)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dictionary_df: pd.DataFrame, path_to_data: str) -> None:\n",
    "    filenames = dictionary_df['Filename'].to_numpy()\n",
    "    speeds = dictionary_df['Speed'].to_numpy()\n",
    "    first_file = True\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        path = f'{path_to_data}{filename}.txt'\n",
    "        data = pd.read_csv(path)\n",
    "        \n",
    "        # rename column names\n",
    "        proccessed_data = rename_observation_columns(data)\n",
    "        \n",
    "        # calculate the velocities\n",
    "        proccessed_data = intergrate_column(proccessed_data)\n",
    "        \n",
    "        # drop gyroscope data\n",
    "        gryo_mask = proccessed_data.columns.str.startswith('gyro')\n",
    "        gyro_columns = proccessed_data.columns[gryo_mask]\n",
    "        proccessed_data = proccessed_data.drop(gyro_columns, axis=1)\n",
    "        \n",
    "        # smooth the imu readings by calculating the rolling average\n",
    "        proccessed_data = proccessed_data.apply(lambda column: rolling_average(column.to_numpy()))\n",
    "        \n",
    "        # find the maximum value on x axis acceleration and slice 100 frames before and after that point\n",
    "        proccessed_data = identify_maximum_acceleration(proccessed_data).reset_index(drop=True)\n",
    "        \n",
    "        # calculate acceleration magnitude \n",
    "        proccessed_data['acceleration_magnitude'] = calculate_vector_magnitude(proccessed_data)\n",
    "        \n",
    "        # calculate acceleration magnitude \n",
    "        proccessed_data['velocity_magnitude'] = calculate_vector_magnitude(proccessed_data,\n",
    "                                                                           'veloc_x', \n",
    "                                                                           'veloc_y', \n",
    "                                                                           'veloc_z')\n",
    "        \n",
    "        # keep only magnitude columns\n",
    "        mag_mask = proccessed_data.columns.str.endswith('magnitude')\n",
    "        magnitude_columns = proccessed_data.columns[mag_mask]\n",
    "        proccessed_data = proccessed_data.loc[:, magnitude_columns]\n",
    "        \n",
    "        # rehsape the values into a single row and re-create the dataframe\n",
    "        column_names = [f'acceleration_{i}' if i < 201 else f'velocity_{i-201}' for i in range(len(proccessed_data) * 2)]\n",
    "        flattened_values = proccessed_data.to_numpy().flatten().reshape(1, -1)\n",
    "        \n",
    "        # reshpe the dataframe into a single row\n",
    "        proccessed_data = pd.DataFrame(flattened_values, columns=column_names)\n",
    "        proccessed_data['speed'] = speeds[i]\n",
    "        \n",
    "        # append the row data into a new document\n",
    "        proccessed_data.to_csv('magnitudes.csv', mode='a', index=False, header=first_file)\n",
    "        first_file = False\n",
    "    \n",
    "    return \n",
    "path = 'raw_imu_data/'     \n",
    "process_data(radar_gun, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration_0</th>\n",
       "      <th>acceleration_1</th>\n",
       "      <th>acceleration_2</th>\n",
       "      <th>acceleration_3</th>\n",
       "      <th>acceleration_4</th>\n",
       "      <th>acceleration_5</th>\n",
       "      <th>acceleration_6</th>\n",
       "      <th>acceleration_7</th>\n",
       "      <th>acceleration_8</th>\n",
       "      <th>acceleration_9</th>\n",
       "      <th>...</th>\n",
       "      <th>velocity_192</th>\n",
       "      <th>velocity_193</th>\n",
       "      <th>velocity_194</th>\n",
       "      <th>velocity_195</th>\n",
       "      <th>velocity_196</th>\n",
       "      <th>velocity_197</th>\n",
       "      <th>velocity_198</th>\n",
       "      <th>velocity_199</th>\n",
       "      <th>velocity_200</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.267806</td>\n",
       "      <td>4.591906</td>\n",
       "      <td>40.939320</td>\n",
       "      <td>4.631849</td>\n",
       "      <td>41.626443</td>\n",
       "      <td>4.673024</td>\n",
       "      <td>42.329588</td>\n",
       "      <td>4.715496</td>\n",
       "      <td>43.049186</td>\n",
       "      <td>4.759334</td>\n",
       "      <td>...</td>\n",
       "      <td>43.878436</td>\n",
       "      <td>69.811863</td>\n",
       "      <td>44.009299</td>\n",
       "      <td>67.931676</td>\n",
       "      <td>44.136299</td>\n",
       "      <td>66.084627</td>\n",
       "      <td>44.259527</td>\n",
       "      <td>64.276220</td>\n",
       "      <td>44.379089</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.353324</td>\n",
       "      <td>6.551532</td>\n",
       "      <td>36.130051</td>\n",
       "      <td>6.608026</td>\n",
       "      <td>36.932782</td>\n",
       "      <td>6.666167</td>\n",
       "      <td>37.764277</td>\n",
       "      <td>6.726039</td>\n",
       "      <td>38.627357</td>\n",
       "      <td>6.787730</td>\n",
       "      <td>...</td>\n",
       "      <td>44.354233</td>\n",
       "      <td>55.460990</td>\n",
       "      <td>44.455643</td>\n",
       "      <td>54.599261</td>\n",
       "      <td>44.555156</td>\n",
       "      <td>53.790989</td>\n",
       "      <td>44.652897</td>\n",
       "      <td>53.033205</td>\n",
       "      <td>44.748986</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.623461</td>\n",
       "      <td>8.793857</td>\n",
       "      <td>20.965851</td>\n",
       "      <td>8.826784</td>\n",
       "      <td>21.321567</td>\n",
       "      <td>8.859985</td>\n",
       "      <td>21.691096</td>\n",
       "      <td>8.893478</td>\n",
       "      <td>22.074893</td>\n",
       "      <td>8.927277</td>\n",
       "      <td>...</td>\n",
       "      <td>37.999374</td>\n",
       "      <td>68.635315</td>\n",
       "      <td>38.123864</td>\n",
       "      <td>67.336328</td>\n",
       "      <td>38.245084</td>\n",
       "      <td>66.041512</td>\n",
       "      <td>38.363000</td>\n",
       "      <td>64.752636</td>\n",
       "      <td>38.477592</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.618824</td>\n",
       "      <td>4.929379</td>\n",
       "      <td>41.235261</td>\n",
       "      <td>4.967951</td>\n",
       "      <td>41.875856</td>\n",
       "      <td>5.007598</td>\n",
       "      <td>42.542012</td>\n",
       "      <td>5.048389</td>\n",
       "      <td>43.235081</td>\n",
       "      <td>5.090397</td>\n",
       "      <td>...</td>\n",
       "      <td>45.849827</td>\n",
       "      <td>72.254275</td>\n",
       "      <td>45.986249</td>\n",
       "      <td>70.498624</td>\n",
       "      <td>46.119135</td>\n",
       "      <td>68.798853</td>\n",
       "      <td>46.248619</td>\n",
       "      <td>67.160491</td>\n",
       "      <td>46.374840</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.808097</td>\n",
       "      <td>4.537868</td>\n",
       "      <td>37.353313</td>\n",
       "      <td>4.590959</td>\n",
       "      <td>37.913555</td>\n",
       "      <td>4.644995</td>\n",
       "      <td>38.489589</td>\n",
       "      <td>4.700011</td>\n",
       "      <td>39.082185</td>\n",
       "      <td>4.756044</td>\n",
       "      <td>...</td>\n",
       "      <td>44.401339</td>\n",
       "      <td>80.399933</td>\n",
       "      <td>44.550592</td>\n",
       "      <td>78.380078</td>\n",
       "      <td>44.695691</td>\n",
       "      <td>76.349556</td>\n",
       "      <td>44.836621</td>\n",
       "      <td>74.315216</td>\n",
       "      <td>44.973379</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>42.666708</td>\n",
       "      <td>15.133016</td>\n",
       "      <td>43.670120</td>\n",
       "      <td>15.215444</td>\n",
       "      <td>44.707731</td>\n",
       "      <td>15.299951</td>\n",
       "      <td>45.781511</td>\n",
       "      <td>15.386617</td>\n",
       "      <td>46.893523</td>\n",
       "      <td>15.475522</td>\n",
       "      <td>...</td>\n",
       "      <td>62.012548</td>\n",
       "      <td>80.139807</td>\n",
       "      <td>62.154105</td>\n",
       "      <td>78.778138</td>\n",
       "      <td>62.292997</td>\n",
       "      <td>77.472685</td>\n",
       "      <td>62.429349</td>\n",
       "      <td>76.223917</td>\n",
       "      <td>62.563282</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>41.159132</td>\n",
       "      <td>12.841350</td>\n",
       "      <td>42.166239</td>\n",
       "      <td>12.923284</td>\n",
       "      <td>43.207505</td>\n",
       "      <td>13.007337</td>\n",
       "      <td>44.284819</td>\n",
       "      <td>13.093582</td>\n",
       "      <td>45.399976</td>\n",
       "      <td>13.182095</td>\n",
       "      <td>...</td>\n",
       "      <td>60.036358</td>\n",
       "      <td>82.291525</td>\n",
       "      <td>60.178619</td>\n",
       "      <td>80.856343</td>\n",
       "      <td>60.318081</td>\n",
       "      <td>79.471956</td>\n",
       "      <td>60.454864</td>\n",
       "      <td>78.139729</td>\n",
       "      <td>60.589082</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>41.275057</td>\n",
       "      <td>16.803493</td>\n",
       "      <td>42.400130</td>\n",
       "      <td>16.886574</td>\n",
       "      <td>43.567725</td>\n",
       "      <td>16.971923</td>\n",
       "      <td>44.779045</td>\n",
       "      <td>17.059623</td>\n",
       "      <td>46.035083</td>\n",
       "      <td>17.149761</td>\n",
       "      <td>...</td>\n",
       "      <td>65.181516</td>\n",
       "      <td>82.393571</td>\n",
       "      <td>65.329952</td>\n",
       "      <td>81.104120</td>\n",
       "      <td>65.475809</td>\n",
       "      <td>79.863011</td>\n",
       "      <td>65.619175</td>\n",
       "      <td>78.668724</td>\n",
       "      <td>65.760131</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>44.129649</td>\n",
       "      <td>12.463115</td>\n",
       "      <td>45.201714</td>\n",
       "      <td>12.549247</td>\n",
       "      <td>46.311676</td>\n",
       "      <td>12.637455</td>\n",
       "      <td>47.461334</td>\n",
       "      <td>12.727820</td>\n",
       "      <td>48.652356</td>\n",
       "      <td>12.820428</td>\n",
       "      <td>...</td>\n",
       "      <td>61.307041</td>\n",
       "      <td>89.573812</td>\n",
       "      <td>61.466654</td>\n",
       "      <td>88.268077</td>\n",
       "      <td>61.623709</td>\n",
       "      <td>87.016205</td>\n",
       "      <td>61.778323</td>\n",
       "      <td>85.817565</td>\n",
       "      <td>61.930604</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>46.315313</td>\n",
       "      <td>16.012791</td>\n",
       "      <td>47.479478</td>\n",
       "      <td>16.104945</td>\n",
       "      <td>48.685422</td>\n",
       "      <td>16.199565</td>\n",
       "      <td>49.934227</td>\n",
       "      <td>16.296737</td>\n",
       "      <td>51.226877</td>\n",
       "      <td>16.396545</td>\n",
       "      <td>...</td>\n",
       "      <td>65.874279</td>\n",
       "      <td>85.573386</td>\n",
       "      <td>66.029410</td>\n",
       "      <td>84.374566</td>\n",
       "      <td>66.182193</td>\n",
       "      <td>83.221981</td>\n",
       "      <td>66.332711</td>\n",
       "      <td>82.113151</td>\n",
       "      <td>66.481039</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acceleration_0  acceleration_1  acceleration_2  acceleration_3  \\\n",
       "0         40.267806        4.591906       40.939320        4.631849   \n",
       "1         35.353324        6.551532       36.130051        6.608026   \n",
       "2         20.623461        8.793857       20.965851        8.826784   \n",
       "3         40.618824        4.929379       41.235261        4.967951   \n",
       "4         36.808097        4.537868       37.353313        4.590959   \n",
       "..              ...             ...             ...             ...   \n",
       "100       42.666708       15.133016       43.670120       15.215444   \n",
       "101       41.159132       12.841350       42.166239       12.923284   \n",
       "102       41.275057       16.803493       42.400130       16.886574   \n",
       "103       44.129649       12.463115       45.201714       12.549247   \n",
       "104       46.315313       16.012791       47.479478       16.104945   \n",
       "\n",
       "     acceleration_4  acceleration_5  acceleration_6  acceleration_7  \\\n",
       "0         41.626443        4.673024       42.329588        4.715496   \n",
       "1         36.932782        6.666167       37.764277        6.726039   \n",
       "2         21.321567        8.859985       21.691096        8.893478   \n",
       "3         41.875856        5.007598       42.542012        5.048389   \n",
       "4         37.913555        4.644995       38.489589        4.700011   \n",
       "..              ...             ...             ...             ...   \n",
       "100       44.707731       15.299951       45.781511       15.386617   \n",
       "101       43.207505       13.007337       44.284819       13.093582   \n",
       "102       43.567725       16.971923       44.779045       17.059623   \n",
       "103       46.311676       12.637455       47.461334       12.727820   \n",
       "104       48.685422       16.199565       49.934227       16.296737   \n",
       "\n",
       "     acceleration_8  acceleration_9  ...  velocity_192  velocity_193  \\\n",
       "0         43.049186        4.759334  ...     43.878436     69.811863   \n",
       "1         38.627357        6.787730  ...     44.354233     55.460990   \n",
       "2         22.074893        8.927277  ...     37.999374     68.635315   \n",
       "3         43.235081        5.090397  ...     45.849827     72.254275   \n",
       "4         39.082185        4.756044  ...     44.401339     80.399933   \n",
       "..              ...             ...  ...           ...           ...   \n",
       "100       46.893523       15.475522  ...     62.012548     80.139807   \n",
       "101       45.399976       13.182095  ...     60.036358     82.291525   \n",
       "102       46.035083       17.149761  ...     65.181516     82.393571   \n",
       "103       48.652356       12.820428  ...     61.307041     89.573812   \n",
       "104       51.226877       16.396545  ...     65.874279     85.573386   \n",
       "\n",
       "     velocity_194  velocity_195  velocity_196  velocity_197  velocity_198  \\\n",
       "0       44.009299     67.931676     44.136299     66.084627     44.259527   \n",
       "1       44.455643     54.599261     44.555156     53.790989     44.652897   \n",
       "2       38.123864     67.336328     38.245084     66.041512     38.363000   \n",
       "3       45.986249     70.498624     46.119135     68.798853     46.248619   \n",
       "4       44.550592     78.380078     44.695691     76.349556     44.836621   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "100     62.154105     78.778138     62.292997     77.472685     62.429349   \n",
       "101     60.178619     80.856343     60.318081     79.471956     60.454864   \n",
       "102     65.329952     81.104120     65.475809     79.863011     65.619175   \n",
       "103     61.466654     88.268077     61.623709     87.016205     61.778323   \n",
       "104     66.029410     84.374566     66.182193     83.221981     66.332711   \n",
       "\n",
       "     velocity_199  velocity_200  speed  \n",
       "0       64.276220     44.379089     59  \n",
       "1       53.033205     44.748986     63  \n",
       "2       64.752636     38.477592     64  \n",
       "3       67.160491     46.374840     65  \n",
       "4       74.315216     44.973379     65  \n",
       "..            ...           ...    ...  \n",
       "100     76.223917     62.563282     84  \n",
       "101     78.139729     60.589082     84  \n",
       "102     78.668724     65.760131     85  \n",
       "103     85.817565     61.930604     85  \n",
       "104     82.113151     66.481039     86  \n",
       "\n",
       "[105 rows x 403 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('magnitudes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the area around the maximum x axis acceleration \n",
    "\n",
    "def identify_maximum_acceleration(df: pd.DataFrame, \n",
    "                                  numeric_column: Optional[str] = 'acc_x') -> pd.DataFrame:\n",
    "    '''\n",
    "    Slices a dataframe to just 100 observations before, and after the maximum value of a numeric value\n",
    "    input:\n",
    "        df: dataframe, renamed columns raw imu file data\n",
    "        numeric_column: string, numeric values column name 'acc_x' by default\n",
    "    '''\n",
    "    # find the index for the maximum value in the numeric column\n",
    "    maximum_idx = df[numeric_column].idxmax()\n",
    "    \n",
    "    # capture 100 frames before and after the maximum value\n",
    "    maximum = df.loc[maximum_idx - 100: maximum_idx + 100]\n",
    "    return maximum\n",
    "\n",
    "    \n",
    "peak_idx = processing_df['acc_x'].idxmax()\n",
    "peak_acc = processing_df.loc[peak_idx - 100:peak_idx + 100 , :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
