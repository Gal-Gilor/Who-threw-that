{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Summary\n",
    "\n",
    "* Rename columns\n",
    "* Focus on acceleration and ignore the angular velocity (for now)\n",
    "* Smoothen the values to help reduce noise\n",
    "* Calculate the acceleration vector magnitude\n",
    "* Focusing on readings near the acceleration peak\n",
    "* Scale the data\n",
    "* Create a training and testing datasets\n",
    "    * Each row would contain the acceleration magnitudes for a single throw (file)\n",
    "    * Append the radar gun reading to the observations\n",
    "    * Optional: Add wrist velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, List, Dict, Union\n",
    "\n",
    "from scipy.integrate import cumtrapz # intergrate trapezoidal rule\n",
    "\n",
    "# graph styling\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-dark')\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_gun = pd.read_csv('Speed-Filenames.csv')\n",
    "radar_gun = radar_gun.sort_values(by=['Speed']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_observation_columns(df: pd.DataFrame, columns: Optional[Dict] = {\n",
    "        \"Time_s_\": \"time\", \n",
    "        \"Acc_x_m_s_2_\": \"acc_x\",\n",
    "        \"Acc_y_m_s_2_\": \"acc_y\",\n",
    "        \"Acc_z_m_s_2_\": \"acc_z\",\n",
    "        \"Gyro_x_1_s_\": \"gyro_x\",\n",
    "        \"Gyro_y_1_s_\": \"gyro_y\",\n",
    "        \"Gyro_z_1_s_\": \"gyro_z\",\n",
    "    }) -> pd.DataFrame:\n",
    "    '''\n",
    "    Rename the column names in the individual throws dataframes\n",
    "    Note: Specific to this kaggle dataset columns\n",
    "    inputs:\n",
    "        df: dataframe, raw imu file data\n",
    "    '''    \n",
    "    return df.rename(columns=columns)\n",
    "\n",
    "def filter_columns(df: pd.DataFrame, regex: Optional[str] = 'acc.*') -> pd.DataFrame:\n",
    "    '''\n",
    "    Keeps only the acceleration columns (start with acc)\n",
    "    inputs:\n",
    "        df: dataframe, renamed columns raw imu file data\n",
    "        regex: string, a regular expression 'acc.*' by default\n",
    "    '''\n",
    "    return df.filter(regex=regex)\n",
    "\n",
    "def rolling_average(vector: np.array, window_width: Optional[int] = 151) -> np.array:\n",
    "    '''\n",
    "    Calculate the rolling average of a vector\n",
    "    input:\n",
    "        vector: numpy array, input to calculate the moving average\n",
    "        window_with: integer, defines how many units in the vector to average together 151 items by default\n",
    "    '''\n",
    "    cumsum_vec = np.cumsum(np.insert(vector, 0, 0))\n",
    "    ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "    return ma_vec\n",
    "\n",
    "def calculate_vector_magnitude(df: pd.DataFrame, \n",
    "                               x_vector: Optional[str] = 'acc_x',\n",
    "                               y_vector: Optional[str] = 'acc_y',\n",
    "                               z_vector: Optional[str] = 'acc_z') -> np.array:\n",
    "    '''\n",
    "    Calculate the magnitude of a 3D vector (x, y, z axis)\n",
    "    The square root the sum of the squared vector values\n",
    "    sqrt(Ax^2 + Ay^2 + Az^2)\n",
    "    input:\n",
    "        df: df: dataframe, renamed columns raw imu file data\n",
    "        x_vector: string, x axis column name 'acc_x' by default\n",
    "        y_vector: string, y axis column name 'acc_y' by default\n",
    "        z_vector: string, z axis column name 'acc_z' by default    \n",
    "    '''\n",
    "    \n",
    "    # square the vectors\n",
    "    x_squared = df[x_vector] ** 2\n",
    "    y_squared = df[y_vector] ** 2\n",
    "    z_squared = df[z_vector] ** 2\n",
    "    \n",
    "    # square root the sum of squared values (magnitude) \n",
    "    return np.sqrt(sum([x_squared + y_squared + z_squared]))\n",
    "\n",
    "def identify_maximum_acceleration(df: pd.DataFrame, \n",
    "                                  numeric_column: Optional[str] = 'acc_x') -> pd.DataFrame:\n",
    "    '''\n",
    "    Slices a dataframe to just 100 observations before, and after the maximum value of a numeric value\n",
    "    input:\n",
    "        df: dataframe, renamed columns raw imu file data\n",
    "        numeric_column: string, numeric values column name 'acc_x' by default\n",
    "    '''\n",
    "    # find the index for the maximum value in the numeric column\n",
    "    maximum_idx = df[numeric_column].idxmax()\n",
    "    \n",
    "    # capture 100 frames before and after the maximum value\n",
    "    maximum = df.loc[maximum_idx - 100: maximum_idx + 100]\n",
    "    return maximum\n",
    "\n",
    "def intergrate_column(df: pd.DataFrame, \n",
    "                      columns_to_integrate: Optional[List[str]] = ['acc_x', 'acc_y', 'acc_z'],\n",
    "                      integrated_columns_names: Optional[List[str]] = ['veloc_x', 'veloc_y', 'veloc_z'],\n",
    "                      x_column: Optional[str] = 'time') -> pd.DataFrame:\n",
    "    '''\n",
    "    Intergrate using the trapezoidal rule the acceleration of the wrist to produce the velocity\n",
    "    input:\n",
    "        df: dataframe, renamed columns raw imu file data\n",
    "        columns_to_integrate: array, list containing columns to integrate\n",
    "        integrated_columns_names: array, list containing names for the new integrated columns\n",
    "        x_column: string, the x axis column name to produce the acceleration function\n",
    "    '''\n",
    "    assert len(integrated_columns_names) == len(columns_to_integrate), \\\n",
    "        \"The new columns name array should be the same length as the columns to integerate array\"   \n",
    "    \n",
    "    for i in range(len(integrated_columns_names)):\n",
    "        df[integrated_columns_names[i]] = np.append(0.0, cumtrapz(df[columns_to_integrate[i]], x=df[x_column])) \n",
    "    return df\n",
    "\n",
    "def scale_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # refrence column names \n",
    "    column_names = df.columns.tolist()\n",
    "    \n",
    "    # instanciate scaler and fit to the dataframe\n",
    "    scaler = StandardScaler()  \n",
    "    scaled_features = scaler.fit_transform(df)\n",
    "    \n",
    "    # create a new dataframe with the scaled features\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=column_names, index=df.index)\n",
    "    return scaled_df\n",
    "\n",
    "def process_data(dictionary_df: pd.DataFrame, path_to_data: str) -> None:\n",
    "    filenames = dictionary_df['Filename'].to_numpy()\n",
    "    speeds = dictionary_df['Speed'].to_numpy()\n",
    "    first_file = True\n",
    "    \n",
    "    try:\n",
    "        for i, filename in enumerate(filenames):\n",
    "            path = f'{path_to_data}{filename}.txt'\n",
    "            data = pd.read_csv(path)\n",
    "\n",
    "            # rename column names\n",
    "            proccessed_data = rename_observation_columns(data)\n",
    "\n",
    "            # calculate the velocities\n",
    "            proccessed_data = intergrate_column(proccessed_data)\n",
    "\n",
    "            # drop gyroscope data\n",
    "            gryo_mask = proccessed_data.columns.str.startswith('gyro')\n",
    "            gyro_columns = proccessed_data.columns[gryo_mask]\n",
    "            proccessed_data = proccessed_data.drop(gyro_columns, axis=1)\n",
    "\n",
    "            # smooth the imu readings by calculating the rolling average\n",
    "            proccessed_data = proccessed_data.apply(lambda column: rolling_average(column.to_numpy()))\n",
    "\n",
    "            # find the maximum value on x axis acceleration and slice 100 frames before and after that point\n",
    "            proccessed_data = identify_maximum_acceleration(proccessed_data).reset_index(drop=True)\n",
    "\n",
    "            # calculate acceleration magnitude \n",
    "            proccessed_data['acceleration_magnitude'] = calculate_vector_magnitude(proccessed_data)\n",
    "\n",
    "            # calculate acceleration magnitude \n",
    "            proccessed_data['velocity_magnitude'] = calculate_vector_magnitude(proccessed_data,\n",
    "                                                                               'veloc_x', \n",
    "                                                                               'veloc_y', \n",
    "                                                                               'veloc_z')\n",
    "\n",
    "            # keep only magnitude columns\n",
    "            mag_mask = proccessed_data.columns.str.endswith('magnitude')\n",
    "            magnitude_columns = proccessed_data.columns[mag_mask]\n",
    "            proccessed_data = proccessed_data.loc[:, magnitude_columns]\n",
    "\n",
    "            # create a standard scaled version of the data\n",
    "            proccessed_data = scale_dataframe(proccessed_data)\n",
    "\n",
    "            # rehsape the values into a single row and re-create the dataframe\n",
    "            column_names = [f'acceleration_{i}' if i < 201 else f'velocity_{i-201}' for i in range(len(proccessed_data) * 2)]\n",
    "            flattened_values = proccessed_data.to_numpy().flatten().reshape(1, -1)\n",
    "\n",
    "            # reshpe the dataframe into a single row\n",
    "            proccessed_data = pd.DataFrame(flattened_values, columns=column_names)\n",
    "            proccessed_data['speed'] = speeds[i]\n",
    "\n",
    "            # append the row data into a new document\n",
    "            proccessed_data.to_csv('magnitudes.csv', mode='a', index=False, header=first_file)\n",
    "            first_file = False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "                      \n",
    "    return proccessed_data\n",
    "\n",
    "path = 'raw_imu_data/'     \n",
    "df = process_data(radar_gun, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
