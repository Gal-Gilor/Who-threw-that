{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "* Rename columns\n",
    "* Focus on acceleration and ignore the angular velocity (for now)\n",
    "* Smoothen the values to help reduce noise\n",
    "* Calculate the acceleration vector magnitude\n",
    "* Focusing on readings near the acceleration peak\n",
    "* Scale the data\n",
    "* Create a training and testing datasets\n",
    "    * Each row would contain the acceleration magnitudes for a single throw (file)\n",
    "    * Append the radar gun reading to the observations\n",
    "    * Optional: Add wrist velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib as jb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from typing import Optional, List, Dict, Union\n",
    "\n",
    "from scipy.integrate import cumtrapz # intergrate trapezoidal rule\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# graph styling\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-dark')\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_gun = pd.read_csv('Speed-Filenames.csv')\n",
    "radar_gun = radar_gun.sort_values(by=['Speed']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_observation_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Rename the column names in the individual throws dataframes\n",
    "    Note: Specific to this kaggle dataset columns\n",
    "    inputs:\n",
    "        df: dataframe, raw imu file data\n",
    "    '''\n",
    "    return df.rename(columns={\n",
    "        \"Time_s_\": \"time\", \n",
    "        \"Acc_x_m_s_2_\": \"acc_x\",\n",
    "        \"Acc_y_m_s_2_\": \"acc_y\",\n",
    "        \"Acc_z_m_s_2_\": \"acc_z\",\n",
    "        \"Gyro_x_1_s_\": \"gyro_x\",\n",
    "        \"Gyro_y_1_s_\": \"gyro_y\",\n",
    "        \"Gyro_z_1_s_\": \"gyro_z\",\n",
    "    })\n",
    "\n",
    "def filter_acceleration_columns(df: pd.DataFrame, regex: Optional[str] = 'acc.*') -> pd.DataFrame:\n",
    "    '''\n",
    "    Keeps only the acceleration columns (start with acc)\n",
    "    inputs:\n",
    "        df: dataframe, raw imu file data\n",
    "        regex: string, a regular expression 'acc.*' by default\n",
    "    '''\n",
    "    return df.filter(regex=regex)\n",
    "\n",
    "def rolling_average(vector: np.array, window_width: int) -> np.array:\n",
    "    '''\n",
    "    Calculate the rolling average of a vector\n",
    "    input:\n",
    "        vector: numpy array, input to calculate the moving average\n",
    "        window_with: integer, defines how many units in the vector to average together\n",
    "    '''\n",
    "    cumsum_vec = np.cumsum(np.insert(vector, 0, 0))\n",
    "    ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
    "    return ma_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dictionary_df, path_to_data):\n",
    "    filenames = dictionary_df['Filename']\n",
    "    speeds = dictionary_df['Speed']\n",
    "    first_file = True\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        path = f'{path_to_data}{filename}.txt'\n",
    "        data = pd.read_csv(path)\n",
    "        \n",
    "        # rename column names\n",
    "        proccessed_data = rename_observation_columns(data)\n",
    "        \n",
    "        # keep the acceleration columns\n",
    "        proccessed_data = filter_acceleration_columns(proccessed_data)\n",
    "        \n",
    "        # establish pipeline steps\n",
    "        pipe = pipeline_steps() \n",
    "        \n",
    "        # fit and transform the data\n",
    "        transormed = pipe.fit_transform(data)\n",
    "        \n",
    "        # append the associated speedometer reading\n",
    "        n_records, _ = transormed.shape\n",
    "        speed = [speeds[i] for _ in range(n_records)]\n",
    "        transormed['speed'] = speed\n",
    "        \n",
    "        # split the acceleration, angular velocity and forward velocity.\n",
    "        # create dataset for each feature\n",
    "        acceleration = transormed.loc[['acc_mag'], :].to_csv('acceleration.csv', \n",
    "                                                              mode='a', index=False, \n",
    "                                                              header=first_file)  \n",
    "        \n",
    "        velocity = transormed.loc[['veloc_mag'], :].to_csv('velocity.csv', \n",
    "                                                            mode='a', index=False, \n",
    "                                                            header=first_file)  \n",
    "        \n",
    "        angular_velocity = transormed.loc[['gyro_mag'], :].to_csv('angular_velocity.csv', \n",
    "                                                                  mode='a', index=False, \n",
    "                                                                  header=first_file)\n",
    "        \n",
    "        first_file = False if i >= 0 and first_file == True else first_file\n",
    "    return \n",
    "     \n",
    "#process_data(speeds_df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
